#!/usr/bin/env python3
"""
ONE Platform - Done Hook
Marks current inference complete and advances to next inference.

This hook runs on Stop event to:
- Mark current inference as complete
- Capture lessons learned (if any)
- Advance to next inference
- Save updated state
"""
import json
import sys
import os
import time
from pathlib import Path
from typing import Dict, Any

# Import task descriptions and helpers from todo hook
from todo import (
    INFERENCE_TASKS,
    get_dimensions_for_inference,
    get_specialist_for_inference,
    get_phase_for_inference,
    get_parallel_opportunities
)


def load_state() -> Dict[str, Any]:
    """Load current inference state from .claude/state/inference.json"""
    state_file = Path(os.environ.get("CLAUDE_PROJECT_DIR", ".")) / ".claude" / "state" / "inference.json"

    if not state_file.exists():
        # Initialize default state
        default_state = {
            "current_inference": 1,
            "completed_inferences": [],
            "feature_name": "New Feature",
            "organization": "Default Org",
            "person_role": "platform_owner",
            "lessons_learned": []
        }
        return default_state

    return json.loads(state_file.read_text())


def save_state(state: Dict[str, Any]):
    """Save inference state to .claude/state/inference.json"""
    state_file = Path(os.environ.get("CLAUDE_PROJECT_DIR", ".")) / ".claude" / "state" / "inference.json"
    state_file.parent.mkdir(parents=True, exist_ok=True)
    state_file.write_text(json.dumps(state, indent=2))


def extract_lesson_from_transcript(transcript_path: str, inference: int) -> str:
    """Extract lesson learned from conversation transcript"""
    try:
        if not transcript_path or not Path(transcript_path).exists():
            return f"Completed Infer {inference}"

        # Read transcript JSONL and extract key learnings
        with open(transcript_path, 'r') as f:
            lines = f.readlines()

        # Look for key phrases in assistant responses
        lessons = []
        for line in lines[-10:]:  # Last 10 messages
            try:
                msg = json.loads(line)
                if msg.get("role") == "assistant":
                    content = msg.get("content", "")
                    # Extract lessons (simple heuristic)
                    if "learned" in content.lower() or "lesson" in content.lower():
                        lessons.append(content[:200])  # First 200 chars
                    elif "success" in content.lower() and len(content) < 300:
                        lessons.append(content)
            except json.JSONDecodeError:
                continue

        if lessons:
            return lessons[-1]  # Most recent lesson
        return f"Completed Infer {inference}"

    except Exception as e:
        return f"Completed Infer {inference} (lesson extraction failed: {str(e)[:50]})"


def mark_complete_and_advance(state: Dict[str, Any], transcript_path: str) -> Dict[str, Any]:
    """Mark current inference complete and advance to next"""
    current = state["current_inference"]

    # Mark current inference as complete
    if current not in state["completed_inferences"]:
        state["completed_inferences"].append(current)
        state["completed_inferences"].sort()

    # Extract lesson learned
    lesson = extract_lesson_from_transcript(transcript_path, current)
    state["lessons_learned"].append({
        "inference": current,
        "lesson": lesson,
        "timestamp": int(time.time())  # Unix timestamp
    })

    # Advance to next inference (unless we're at 100)
    if current < 100:
        state["current_inference"] = current + 1
    else:
        # Feature complete!
        state["current_inference"] = 100
        state["feature_complete"] = True

    return state


def generate_completion_message(state: Dict[str, Any]) -> str:
    """Generate message shown after marking complete"""
    previous = state["current_inference"] - 1 if state["current_inference"] > 1 else 1
    current = state["current_inference"]
    completed_count = len(state["completed_inferences"])
    progress_pct = (completed_count / 100) * 100

    # Get info for next inference
    task = INFERENCE_TASKS.get(current, "Unknown task")
    phase = get_phase_for_inference(current)
    dimensions = get_dimensions_for_inference(current)
    specialist = get_specialist_for_inference(current)
    parallel_ops = get_parallel_opportunities(current)

    # Get most recent lesson
    recent_lesson = None
    if state.get("lessons_learned"):
        for lesson in reversed(state["lessons_learned"]):
            if lesson["inference"] == previous and lesson["lesson"] != f"Completed Infer {previous}":
                recent_lesson = lesson["lesson"]
                break

    message = f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… INFERENCE COMPLETE: Infer {previous}/100
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Progress:** {completed_count}/100 inferences complete ({progress_pct:.0f}%)
**Feature:** {state["feature_name"]}
"""

    if recent_lesson:
        message += f"\nğŸ’¡ **Lesson Captured:** {recent_lesson[:150]}...\n"

    message += f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{phase['icon']} NEXT INFERENCE: Infer {current}/100
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Phase {phase['number']}/10:** {phase['name']} ({phase['progress']})
**Task:** {task}

**6-Dimension Ontology:** {", ".join(dimensions) if dimensions else "Foundation (all dimensions)"}
**Assigned Specialist:** {specialist if specialist else "director"}
"""

    if parallel_ops:
        message += f"\nâš¡ **Parallel Opportunities:** {', '.join(parallel_ops)}\n"

    message += """
Ready to continue? Type your next prompt or use:
  /done     - Mark this inference complete (when finished)
  /next     - Skip to next inference (if not applicable)
  /reset    - Start new feature (reset to Infer 1)
  /plan     - View complete 100-inference plan

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

    # Special message when feature is complete
    if completed_count == 100:
        meaningful_lessons = [l for l in state.get("lessons_learned", [])
                            if l["lesson"] != f"Completed Infer {l['inference']}"]

        message = f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‰ FEATURE COMPLETE: {state["feature_name"]}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**All 100 inferences completed successfully!**

**Final Stats:**
- Organization: {state["organization"]}
- Person Role: {state["person_role"]}
- Lessons Learned: {len(meaningful_lessons)} meaningful insights captured

**Next Steps:**
1. Start new feature: /reset (or create new conversation)
2. Review all lessons: Check .claude/state/inference.json
3. Deploy to production: /release

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Congratulations! ğŸŠ Your feature is production-ready.
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

    return message


def main():
    try:
        # Load hook input from stdin
        input_data = json.load(sys.stdin)
        transcript_path = input_data.get("transcript_path", "")

        # Load current state
        state = load_state()

        # Mark complete and advance
        state = mark_complete_and_advance(state, transcript_path)

        # Save updated state
        save_state(state)

        # Generate completion message
        message = generate_completion_message(state)

        # Output message (shown in transcript mode with Ctrl-R)
        print(message)

        # Exit with success
        sys.exit(0)

    except Exception as e:
        # Log error but don't block
        print(f"Error in done hook: {e}", file=sys.stderr)
        sys.exit(0)


if __name__ == "__main__":
    main()
