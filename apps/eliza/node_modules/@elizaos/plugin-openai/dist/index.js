// src/index.ts
import { createOpenAI } from "@ai-sdk/openai";
import { EventType, logger, ModelType, VECTOR_DIMS } from "@elizaos/core";
import {
  generateObject,
  generateText,
  JSONParseError
} from "ai";
import { encodingForModel } from "js-tiktoken";
import { fetch, FormData } from "undici";
function getSetting(runtime, key, defaultValue) {
  return runtime.getSetting(key) ?? process.env[key] ?? defaultValue;
}
function getBaseURL(runtime) {
  const baseURL = getSetting(runtime, "OPENAI_BASE_URL", "https://api.openai.com/v1");
  logger.debug(`[OpenAI] Default base URL: ${baseURL}`);
  return baseURL;
}
function getEmbeddingBaseURL(runtime) {
  const embeddingURL = getSetting(runtime, "OPENAI_EMBEDDING_URL");
  if (embeddingURL) {
    logger.debug(`[OpenAI] Using specific embedding base URL: ${embeddingURL}`);
    return embeddingURL;
  }
  logger.debug("[OpenAI] Falling back to general base URL for embeddings.");
  return getBaseURL(runtime);
}
function getApiKey(runtime) {
  return getSetting(runtime, "OPENAI_API_KEY");
}
function getEmbeddingApiKey(runtime) {
  const embeddingApiKey = getSetting(runtime, "OPENAI_EMBEDDING_API_KEY");
  if (embeddingApiKey) {
    logger.debug(`[OpenAI] Using specific embedding API key: ${embeddingApiKey}`);
    return embeddingApiKey;
  }
  logger.debug("[OpenAI] Falling back to general API key for embeddings.");
  return getApiKey(runtime);
}
function getSmallModel(runtime) {
  return getSetting(runtime, "OPENAI_SMALL_MODEL") ?? getSetting(runtime, "SMALL_MODEL", "gpt-5-nano");
}
function getLargeModel(runtime) {
  return getSetting(runtime, "OPENAI_LARGE_MODEL") ?? getSetting(runtime, "LARGE_MODEL", "gpt-5-mini");
}
function getImageDescriptionModel(runtime) {
  return getSetting(runtime, "OPENAI_IMAGE_DESCRIPTION_MODEL", "gpt-5-nano") ?? "gpt-5-nano";
}
function getExperimentalTelemetry(runtime) {
  const setting = getSetting(runtime, "OPENAI_EXPERIMENTAL_TELEMETRY", "false");
  const normalizedSetting = String(setting).toLowerCase();
  const result = normalizedSetting === "true";
  logger.debug(
    `[OpenAI] Experimental telemetry in function: "${setting}" (type: ${typeof setting}, normalized: "${normalizedSetting}", result: ${result})`
  );
  return result;
}
function createOpenAIClient(runtime) {
  return createOpenAI({
    apiKey: getApiKey(runtime),
    baseURL: getBaseURL(runtime)
  });
}
async function tokenizeText(model, prompt) {
  const modelName = model === ModelType.TEXT_SMALL ? process.env.OPENAI_SMALL_MODEL ?? process.env.SMALL_MODEL ?? "gpt-5-nano" : process.env.LARGE_MODEL ?? "gpt-5-mini";
  const encoding = encodingForModel(modelName);
  const tokens = encoding.encode(prompt);
  return tokens;
}
async function detokenizeText(model, tokens) {
  const modelName = model === ModelType.TEXT_SMALL ? process.env.OPENAI_SMALL_MODEL ?? process.env.SMALL_MODEL ?? "gpt-5-nano" : process.env.OPENAI_LARGE_MODEL ?? process.env.LARGE_MODEL ?? "gpt-5-mini";
  const encoding = encodingForModel(modelName);
  return encoding.decode(tokens);
}
async function generateObjectByModelType(runtime, params, modelType, getModelFn) {
  const openai = createOpenAIClient(runtime);
  const modelName = getModelFn(runtime);
  logger.log(`[OpenAI] Using ${modelType} model: ${modelName}`);
  const temperature = params.temperature ?? 0;
  const schemaPresent = !!params.schema;
  if (schemaPresent) {
    logger.info(
      `Using ${modelType} without schema validation (schema provided but output=no-schema)`
    );
  }
  try {
    const { object, usage } = await generateObject({
      model: openai.languageModel(modelName),
      output: "no-schema",
      prompt: params.prompt,
      temperature,
      experimental_repairText: getJsonRepairFunction()
    });
    if (usage) {
      emitModelUsageEvent(runtime, modelType, params.prompt, usage);
    }
    return object;
  } catch (error) {
    if (error instanceof JSONParseError) {
      logger.error(`[generateObject] Failed to parse JSON: ${error.message}`);
      const repairFunction = getJsonRepairFunction();
      const repairedJsonString = await repairFunction({
        text: error.text,
        error
      });
      if (repairedJsonString) {
        try {
          const repairedObject = JSON.parse(repairedJsonString);
          logger.info("[generateObject] Successfully repaired JSON.");
          return repairedObject;
        } catch (repairParseError) {
          const message = repairParseError instanceof Error ? repairParseError.message : String(repairParseError);
          logger.error(`[generateObject] Failed to parse repaired JSON: ${message}`);
          throw repairParseError;
        }
      } else {
        logger.error("[generateObject] JSON repair failed.");
        throw error;
      }
    } else {
      const message = error instanceof Error ? error.message : String(error);
      logger.error(`[generateObject] Unknown error: ${message}`);
      throw error;
    }
  }
}
function getJsonRepairFunction() {
  return async ({ text, error }) => {
    try {
      if (error instanceof JSONParseError) {
        const cleanedText = text.replace(/```json\n|\n```|```/g, "");
        JSON.parse(cleanedText);
        return cleanedText;
      }
      return null;
    } catch (jsonError) {
      const message = jsonError instanceof Error ? jsonError.message : String(jsonError);
      logger.warn(`Failed to repair JSON text: ${message}`);
      return null;
    }
  };
}
function emitModelUsageEvent(runtime, type, prompt, usage) {
  runtime.emitEvent(EventType.MODEL_USED, {
    provider: "openai",
    type,
    prompt,
    tokens: {
      prompt: usage.promptTokens,
      completion: usage.completionTokens,
      total: usage.totalTokens
    }
  });
}
async function fetchTextToSpeech(runtime, text) {
  const apiKey = getApiKey(runtime);
  const model = getSetting(runtime, "OPENAI_TTS_MODEL", "gpt-4o-mini-tts");
  const voice = getSetting(runtime, "OPENAI_TTS_VOICE", "nova");
  const instructions = getSetting(runtime, "OPENAI_TTS_INSTRUCTIONS", "");
  const baseURL = getBaseURL(runtime);
  try {
    const res = await fetch(`${baseURL}/audio/speech`, {
      method: "POST",
      headers: {
        Authorization: `Bearer ${apiKey}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model,
        voice,
        input: text,
        ...instructions && { instructions }
      })
    });
    if (!res.ok) {
      const err = await res.text();
      throw new Error(`OpenAI TTS error ${res.status}: ${err}`);
    }
    return res.body;
  } catch (err) {
    const message = err instanceof Error ? err.message : String(err);
    throw new Error(`Failed to fetch speech from OpenAI TTS: ${message}`);
  }
}
var openaiPlugin = {
  name: "openai",
  description: "OpenAI plugin",
  config: {
    OPENAI_API_KEY: process.env.OPENAI_API_KEY,
    OPENAI_BASE_URL: process.env.OPENAI_BASE_URL,
    OPENAI_SMALL_MODEL: process.env.OPENAI_SMALL_MODEL,
    OPENAI_LARGE_MODEL: process.env.OPENAI_LARGE_MODEL,
    SMALL_MODEL: process.env.SMALL_MODEL,
    LARGE_MODEL: process.env.LARGE_MODEL,
    OPENAI_EMBEDDING_MODEL: process.env.OPENAI_EMBEDDING_MODEL,
    OPENAI_EMBEDDING_API_KEY: process.env.OPENAI_EMBEDDING_API_KEY,
    OPENAI_EMBEDDING_URL: process.env.OPENAI_EMBEDDING_URL,
    OPENAI_EMBEDDING_DIMENSIONS: process.env.OPENAI_EMBEDDING_DIMENSIONS,
    OPENAI_IMAGE_DESCRIPTION_MODEL: process.env.OPENAI_IMAGE_DESCRIPTION_MODEL,
    OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS: process.env.OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS,
    OPENAI_EXPERIMENTAL_TELEMETRY: process.env.OPENAI_EXPERIMENTAL_TELEMETRY
  },
  async init(_config, runtime) {
    new Promise(async (resolve) => {
      resolve();
      try {
        if (!getApiKey(runtime)) {
          logger.warn(
            "OPENAI_API_KEY is not set in environment - OpenAI functionality will be limited"
          );
          return;
        }
        try {
          const baseURL = getBaseURL(runtime);
          const response = await fetch(`${baseURL}/models`, {
            headers: { Authorization: `Bearer ${getApiKey(runtime)}` }
          });
          if (!response.ok) {
            logger.warn(`OpenAI API key validation failed: ${response.statusText}`);
            logger.warn("OpenAI functionality will be limited until a valid API key is provided");
          } else {
            logger.log("OpenAI API key validated successfully");
          }
        } catch (fetchError) {
          const message = fetchError instanceof Error ? fetchError.message : String(fetchError);
          logger.warn(`Error validating OpenAI API key: ${message}`);
          logger.warn("OpenAI functionality will be limited until a valid API key is provided");
        }
      } catch (error) {
        const message = error?.errors?.map((e) => e.message).join(", ") || (error instanceof Error ? error.message : String(error));
        logger.warn(
          `OpenAI plugin configuration issue: ${message} - You need to configure the OPENAI_API_KEY in your environment variables`
        );
      }
    });
  },
  models: {
    [ModelType.TEXT_EMBEDDING]: async (runtime, params) => {
      const embeddingModelName = getSetting(
        runtime,
        "OPENAI_EMBEDDING_MODEL",
        "text-embedding-3-small"
      );
      const embeddingDimension = Number.parseInt(
        getSetting(runtime, "OPENAI_EMBEDDING_DIMENSIONS", "1536") || "1536",
        10
      );
      if (!Object.values(VECTOR_DIMS).includes(embeddingDimension)) {
        const errorMsg = `Invalid embedding dimension: ${embeddingDimension}. Must be one of: ${Object.values(VECTOR_DIMS).join(", ")}`;
        logger.error(errorMsg);
        throw new Error(errorMsg);
      }
      if (params === null) {
        logger.debug("Creating test embedding for initialization");
        const testVector = Array(embeddingDimension).fill(0);
        testVector[0] = 0.1;
        return testVector;
      }
      let text;
      if (typeof params === "string") {
        text = params;
      } else if (typeof params === "object" && params.text) {
        text = params.text;
      } else {
        logger.warn("Invalid input format for embedding");
        const fallbackVector = Array(embeddingDimension).fill(0);
        fallbackVector[0] = 0.2;
        return fallbackVector;
      }
      if (!text.trim()) {
        logger.warn("Empty text for embedding");
        const emptyVector = Array(embeddingDimension).fill(0);
        emptyVector[0] = 0.3;
        return emptyVector;
      }
      const embeddingBaseURL = getEmbeddingBaseURL(runtime);
      const apiKey = getEmbeddingApiKey(runtime);
      if (!apiKey) {
        throw new Error("OpenAI API key not configured");
      }
      try {
        const response = await fetch(`${embeddingBaseURL}/embeddings`, {
          method: "POST",
          headers: {
            Authorization: `Bearer ${apiKey}`,
            "Content-Type": "application/json"
          },
          body: JSON.stringify({
            model: embeddingModelName,
            input: text
          })
        });
        const responseClone = response.clone();
        const rawResponseBody = await responseClone.text();
        if (!response.ok) {
          logger.error(`OpenAI API error: ${response.status} - ${response.statusText}`);
          const errorVector = Array(embeddingDimension).fill(0);
          errorVector[0] = 0.4;
          return errorVector;
        }
        const data = await response.json();
        if (!data?.data?.[0]?.embedding) {
          logger.error("API returned invalid structure");
          const errorVector = Array(embeddingDimension).fill(0);
          errorVector[0] = 0.5;
          return errorVector;
        }
        const embedding = data.data[0].embedding;
        if (data.usage) {
          const usage = {
            promptTokens: data.usage.prompt_tokens,
            completionTokens: 0,
            totalTokens: data.usage.total_tokens
          };
          emitModelUsageEvent(runtime, ModelType.TEXT_EMBEDDING, text, usage);
        }
        logger.log(`Got valid embedding with length ${embedding.length}`);
        return embedding;
      } catch (error) {
        const message = error instanceof Error ? error.message : String(error);
        logger.error(`Error generating embedding: ${message}`);
        const errorVector = Array(embeddingDimension).fill(0);
        errorVector[0] = 0.6;
        return errorVector;
      }
    },
    [ModelType.TEXT_TOKENIZER_ENCODE]: async (_runtime, { prompt, modelType = ModelType.TEXT_LARGE }) => {
      return await tokenizeText(modelType ?? ModelType.TEXT_LARGE, prompt);
    },
    [ModelType.TEXT_TOKENIZER_DECODE]: async (_runtime, { tokens, modelType = ModelType.TEXT_LARGE }) => {
      return await detokenizeText(modelType ?? ModelType.TEXT_LARGE, tokens);
    },
    [ModelType.TEXT_SMALL]: async (runtime, {
      prompt,
      stopSequences = [],
      maxTokens = 8192,
      temperature = 0.7,
      frequencyPenalty = 0.7,
      presencePenalty = 0.7
    }) => {
      const openai = createOpenAIClient(runtime);
      const modelName = getSmallModel(runtime);
      const experimentalTelemetry = getExperimentalTelemetry(runtime);
      logger.log(`[OpenAI] Using TEXT_SMALL model: ${modelName}`);
      logger.log(prompt);
      const { text: openaiResponse, usage } = await generateText({
        model: openai.languageModel(modelName),
        prompt,
        system: runtime.character.system ?? void 0,
        temperature,
        maxTokens,
        frequencyPenalty,
        presencePenalty,
        stopSequences,
        experimental_telemetry: {
          isEnabled: experimentalTelemetry
        }
      });
      if (usage) {
        emitModelUsageEvent(runtime, ModelType.TEXT_SMALL, prompt, usage);
      }
      return openaiResponse;
    },
    [ModelType.TEXT_LARGE]: async (runtime, {
      prompt,
      stopSequences = [],
      maxTokens = 8192,
      temperature = 0.7,
      frequencyPenalty = 0.7,
      presencePenalty = 0.7
    }) => {
      const openai = createOpenAIClient(runtime);
      const modelName = getLargeModel(runtime);
      const experimentalTelemetry = getExperimentalTelemetry(runtime);
      logger.log(`[OpenAI] Using TEXT_LARGE model: ${modelName}`);
      logger.log(prompt);
      const { text: openaiResponse, usage } = await generateText({
        model: openai.languageModel(modelName),
        prompt,
        system: runtime.character.system ?? void 0,
        temperature,
        maxTokens,
        frequencyPenalty,
        presencePenalty,
        stopSequences,
        experimental_telemetry: {
          isEnabled: experimentalTelemetry
        }
      });
      if (usage) {
        emitModelUsageEvent(runtime, ModelType.TEXT_LARGE, prompt, usage);
      }
      return openaiResponse;
    },
    [ModelType.IMAGE]: async (runtime, params) => {
      const n = params.n || 1;
      const size = params.size || "1024x1024";
      const prompt = params.prompt;
      const modelName = "dall-e-3";
      logger.log(`[OpenAI] Using IMAGE model: ${modelName}`);
      const baseURL = getBaseURL(runtime);
      const apiKey = getApiKey(runtime);
      if (!apiKey) {
        throw new Error("OpenAI API key not configured");
      }
      try {
        const response = await fetch(`${baseURL}/images/generations`, {
          method: "POST",
          headers: {
            Authorization: `Bearer ${apiKey}`,
            "Content-Type": "application/json"
          },
          body: JSON.stringify({
            prompt,
            n,
            size
          })
        });
        const responseClone = response.clone();
        const rawResponseBody = await responseClone.text();
        if (!response.ok) {
          throw new Error(`Failed to generate image: ${response.statusText}`);
        }
        const data = await response.json();
        const typedData = data;
        return typedData.data;
      } catch (error) {
        const message = error instanceof Error ? error.message : String(error);
        throw error;
      }
    },
    [ModelType.IMAGE_DESCRIPTION]: async (runtime, params) => {
      let imageUrl;
      let promptText;
      const modelName = getImageDescriptionModel(runtime);
      logger.log(`[OpenAI] Using IMAGE_DESCRIPTION model: ${modelName}`);
      const maxTokens = Number.parseInt(
        getSetting(runtime, "OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS", "8192") || "8192",
        10
      );
      if (typeof params === "string") {
        imageUrl = params;
        promptText = "Please analyze this image and provide a title and detailed description.";
      } else {
        imageUrl = params.imageUrl;
        promptText = params.prompt || "Please analyze this image and provide a title and detailed description.";
      }
      const messages = [
        {
          role: "user",
          content: [
            { type: "text", text: promptText },
            { type: "image_url", image_url: { url: imageUrl } }
          ]
        }
      ];
      const baseURL = getBaseURL(runtime);
      const apiKey = getApiKey(runtime);
      if (!apiKey) {
        logger.error("OpenAI API key not set");
        return {
          title: "Failed to analyze image",
          description: "API key not configured"
        };
      }
      try {
        const requestBody = {
          model: modelName,
          messages,
          max_tokens: maxTokens
        };
        const response = await fetch(`${baseURL}/chat/completions`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer ${apiKey}`
          },
          body: JSON.stringify(requestBody)
        });
        const responseClone = response.clone();
        const rawResponseBody = await responseClone.text();
        if (!response.ok) {
          throw new Error(`OpenAI API error: ${response.status}`);
        }
        const result = await response.json();
        const typedResult = result;
        const content = typedResult.choices?.[0]?.message?.content;
        if (typedResult.usage) {
          emitModelUsageEvent(
            runtime,
            ModelType.IMAGE_DESCRIPTION,
            typeof params === "string" ? params : params.prompt || "",
            {
              promptTokens: typedResult.usage.prompt_tokens,
              completionTokens: typedResult.usage.completion_tokens,
              totalTokens: typedResult.usage.total_tokens
            }
          );
        }
        if (!content) {
          return {
            title: "Failed to analyze image",
            description: "No response from API"
          };
        }
        const isCustomPrompt = typeof params === "object" && params.prompt && params.prompt !== "Please analyze this image and provide a title and detailed description.";
        if (isCustomPrompt) {
          return content;
        }
        const titleMatch = content.match(/title[:\s]+(.+?)(?:\n|$)/i);
        const title = titleMatch?.[1]?.trim() || "Image Analysis";
        const description = content.replace(/title[:\s]+(.+?)(?:\n|$)/i, "").trim();
        const processedResult = { title, description };
        return processedResult;
      } catch (error) {
        const message = error instanceof Error ? error.message : String(error);
        logger.error(`Error analyzing image: ${message}`);
        return {
          title: "Failed to analyze image",
          description: `Error: ${message}`
        };
      }
    },
    [ModelType.TRANSCRIPTION]: async (runtime, audioBuffer) => {
      logger.log({ audioBuffer }, "audioBuffer");
      const modelName = "whisper-1";
      logger.log(`[OpenAI] Using TRANSCRIPTION model: ${modelName}`);
      const baseURL = getBaseURL(runtime);
      const apiKey = getApiKey(runtime);
      if (!apiKey) {
        throw new Error("OpenAI API key not configured - Cannot make request");
      }
      if (!audioBuffer || audioBuffer.length === 0) {
        throw new Error("Audio buffer is empty or invalid for transcription");
      }
      const formData = new FormData();
      formData.append("file", new Blob([audioBuffer]), "recording.mp3");
      formData.append("model", "whisper-1");
      try {
        const response = await fetch(`${baseURL}/audio/transcriptions`, {
          method: "POST",
          headers: {
            Authorization: `Bearer ${apiKey}`
          },
          body: formData
        });
        const responseClone = response.clone();
        const rawResponseBody = await responseClone.text();
        logger.log({ response }, "response");
        if (!response.ok) {
          throw new Error(`Failed to transcribe audio: ${response.statusText}`);
        }
        const data = await response.json();
        const processedText = data.text;
        return processedText;
      } catch (error) {
        const message = error instanceof Error ? error.message : String(error);
        throw error;
      }
    },
    [ModelType.TEXT_TO_SPEECH]: async (runtime, text) => {
      const ttsModelName = getSetting(runtime, "OPENAI_TTS_MODEL", "gpt-4o-mini-tts");
      logger.log(`[OpenAI] Using TEXT_TO_SPEECH model: ${ttsModelName}`);
      try {
        const speechStream = await fetchTextToSpeech(runtime, text);
        return speechStream;
      } catch (error) {
        const message = error instanceof Error ? error.message : String(error);
        throw error;
      }
    },
    [ModelType.OBJECT_SMALL]: async (runtime, params) => {
      return generateObjectByModelType(runtime, params, ModelType.OBJECT_SMALL, getSmallModel);
    },
    [ModelType.OBJECT_LARGE]: async (runtime, params) => {
      return generateObjectByModelType(runtime, params, ModelType.OBJECT_LARGE, getLargeModel);
    }
  },
  tests: [
    {
      name: "openai_plugin_tests",
      tests: [
        {
          name: "openai_test_url_and_api_key_validation",
          fn: async (runtime) => {
            const baseURL = getBaseURL(runtime);
            const response = await fetch(`${baseURL}/models`, {
              headers: {
                Authorization: `Bearer ${getApiKey(runtime)}`
              }
            });
            const data = await response.json();
            logger.log(
              { data: data?.data?.length ?? "N/A" },
              "Models Available"
            );
            if (!response.ok) {
              throw new Error(`Failed to validate OpenAI API key: ${response.statusText}`);
            }
          }
        },
        {
          name: "openai_test_text_embedding",
          fn: async (runtime) => {
            try {
              const embedding = await runtime.useModel(ModelType.TEXT_EMBEDDING, {
                text: "Hello, world!"
              });
              logger.log({ embedding }, "embedding");
            } catch (error) {
              const message = error instanceof Error ? error.message : String(error);
              logger.error(`Error in test_text_embedding: ${message}`);
              throw error;
            }
          }
        },
        {
          name: "openai_test_text_large",
          fn: async (runtime) => {
            try {
              const text = await runtime.useModel(ModelType.TEXT_LARGE, {
                prompt: "What is the nature of reality in 10 words?"
              });
              if (text.length === 0) {
                throw new Error("Failed to generate text");
              }
              logger.log({ text }, "generated with test_text_large");
            } catch (error) {
              const message = error instanceof Error ? error.message : String(error);
              logger.error(`Error in test_text_large: ${message}`);
              throw error;
            }
          }
        },
        {
          name: "openai_test_text_small",
          fn: async (runtime) => {
            try {
              const text = await runtime.useModel(ModelType.TEXT_SMALL, {
                prompt: "What is the nature of reality in 10 words?"
              });
              if (text.length === 0) {
                throw new Error("Failed to generate text");
              }
              logger.log({ text }, "generated with test_text_small");
            } catch (error) {
              const message = error instanceof Error ? error.message : String(error);
              logger.error(`Error in test_text_small: ${message}`);
              throw error;
            }
          }
        },
        {
          name: "openai_test_image_generation",
          fn: async (runtime) => {
            logger.log("openai_test_image_generation");
            try {
              const image = await runtime.useModel(ModelType.IMAGE, {
                prompt: "A beautiful sunset over a calm ocean",
                n: 1,
                size: "1024x1024"
              });
              logger.log({ image }, "generated with test_image_generation");
            } catch (error) {
              const message = error instanceof Error ? error.message : String(error);
              logger.error(`Error in test_image_generation: ${message}`);
              throw error;
            }
          }
        },
        {
          name: "image-description",
          fn: async (runtime) => {
            try {
              logger.log("openai_test_image_description");
              try {
                const result = await runtime.useModel(
                  ModelType.IMAGE_DESCRIPTION,
                  "https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Vitalik_Buterin_TechCrunch_London_2015_%28cropped%29.jpg/537px-Vitalik_Buterin_TechCrunch_London_2015_%28cropped%29.jpg"
                );
                if (result && typeof result === "object" && "title" in result && "description" in result) {
                  logger.log({ result }, "Image description");
                } else {
                  logger.error("Invalid image description result format:", result);
                }
              } catch (e) {
                const message = e instanceof Error ? e.message : String(e);
                logger.error(`Error in image description test: ${message}`);
              }
            } catch (e) {
              const message = e instanceof Error ? e.message : String(e);
              logger.error(`Error in openai_test_image_description: ${message}`);
            }
          }
        },
        {
          name: "openai_test_transcription",
          fn: async (runtime) => {
            logger.log("openai_test_transcription");
            try {
              const response = await fetch(
                "https://upload.wikimedia.org/wikipedia/en/4/40/Chris_Benoit_Voice_Message.ogg"
              );
              const arrayBuffer = await response.arrayBuffer();
              const transcription = await runtime.useModel(
                ModelType.TRANSCRIPTION,
                Buffer.from(new Uint8Array(arrayBuffer))
              );
              logger.log({ transcription }, "generated with test_transcription");
            } catch (error) {
              const message = error instanceof Error ? error.message : String(error);
              logger.error(`Error in test_transcription: ${message}`);
              throw error;
            }
          }
        },
        {
          name: "openai_test_text_tokenizer_encode",
          fn: async (runtime) => {
            const prompt = "Hello tokenizer encode!";
            const tokens = await runtime.useModel(ModelType.TEXT_TOKENIZER_ENCODE, { prompt });
            if (!Array.isArray(tokens) || tokens.length === 0) {
              throw new Error("Failed to tokenize text: expected non-empty array of tokens");
            }
            logger.log({ tokens }, "Tokenized output");
          }
        },
        {
          name: "openai_test_text_tokenizer_decode",
          fn: async (runtime) => {
            const prompt = "Hello tokenizer decode!";
            const tokens = await runtime.useModel(ModelType.TEXT_TOKENIZER_ENCODE, { prompt });
            const decodedText = await runtime.useModel(ModelType.TEXT_TOKENIZER_DECODE, { tokens });
            if (decodedText !== prompt) {
              throw new Error(
                `Decoded text does not match original. Expected "${prompt}", got "${decodedText}"`
              );
            }
            logger.log({ decodedText }, "Decoded text");
          }
        },
        {
          name: "openai_test_text_to_speech",
          fn: async (runtime) => {
            try {
              const text = "Hello, this is a test for text-to-speech.";
              const response = await fetchTextToSpeech(runtime, text);
              if (!response) {
                throw new Error("Failed to generate speech");
              }
              logger.log("Generated speech successfully");
            } catch (error) {
              const message = error instanceof Error ? error.message : String(error);
              logger.error(`Error in openai_test_text_to_speech: ${message}`);
              throw error;
            }
          }
        }
      ]
    }
  ]
};
var index_default = openaiPlugin;
export {
  index_default as default,
  openaiPlugin
};
//# sourceMappingURL=index.js.map